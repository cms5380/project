{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_model_nsmc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1r7ir_-xze4lTvL8SgCSYH8rWA8Y19Re-",
      "authorship_tag": "ABX9TyOAY010ZZ5/Cd2vG2RlGVkL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cms5380/project/blob/master/Bert_model_nsmc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cgj9RLFtxpvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import argparse\n",
        "%tensorflow_version 2.x\n",
        "from sklearn.model_selection import GroupKFold\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install tqdm --upgrade\n",
        "!pip install tensorflow_hub\n",
        "import tensorflow_hub as hub\n",
        "from tqdm import tqdm_notebook, trange\n",
        "from tqdm.notebook import tqdm\n",
        "!pip install transformers\n",
        "from transformers import *\n",
        "import torch\n",
        "import seaborn as sns\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/ML/HanBert-54kN/')\n",
        "import tokenization\n",
        "# import modeling\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeOABs8zz-NF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_inputs(text, tokenizer,max_seq_len):\n",
        "    def return_id(str1,length):\n",
        "        token = tokenizer.tokenize(text)\n",
        "        if len(token) > max_seq_len-2:\n",
        "            token = token[:max_seq_len-2]\n",
        "\n",
        "        inputs_ids = tokenizer.convert_tokens_to_ids(token)    \n",
        "        inputs_ids = [cls_token_id] + inputs_ids + [sep_token_id]\n",
        "        input_mask = [1] * len(inputs_ids) #attention_mask\n",
        "\n",
        "        padding_length = length - len(inputs_ids)\n",
        "        inputs_ids = inputs_ids + ([0] * padding_length)\n",
        "        input_mask = input_mask + ([0] * padding_length)\n",
        "        segment_ids = [0] * len(inputs_ids) #token_type_ids\n",
        "        return [inputs_ids, input_mask, segment_ids]\n",
        "\n",
        "    input_ids, input_masks, input_segments = return_id(text, max_seq_len)\n",
        "\n",
        "    return [input_ids, input_masks, input_segments]\n",
        "\n",
        "def compute_inputs(df, tokenizer, max_sequence_length):\n",
        "    input_ids, segment_ids, input_mask = [], [], []\n",
        "    for document in df['document']:\n",
        "        inp_ids, inp_mask, seg_ids = convert_to_inputs(document, tokenizer, max_sequence_length)\n",
        "\n",
        "        input_ids.append(inp_ids)\n",
        "        segment_ids.append(seg_ids)\n",
        "        input_mask.append(inp_mask)\n",
        "    return [np.asarray(input_ids, dtype=np.int32),\n",
        "            np.asarray(input_mask, dtype=np.int32), \n",
        "            np.asarray(segment_ids, dtype=np.int32)]\n",
        "def compute_outputs(df):\n",
        "    return np.asarray(df['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD8iXtONEahk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_table('/content/gdrive/My Drive/test/ratings_train.txt')\n",
        "test_data = pd.read_table('/content/gdrive/My Drive/test/ratings_test.txt')\n",
        "\n",
        "\n",
        "# train_data['label'].value_counts().plot(kind = 'bar')\n",
        "# plt.show()\n",
        "# print(train_data.isnull().values.any())\n",
        "# print(train_data.isnull().sum())\n",
        "# print(test_data.isnull().values.any())\n",
        "# print(test_data.isnull().sum())\n",
        "\n",
        "# print(train_data.loc[train_data.document.isnull()])\n",
        "train_data = train_data.dropna(how = 'any')\n",
        "# print(train_data.isnull().values.any())\n",
        "test_data = test_data.dropna(how = 'any')\n",
        "# print(train_data.isnull().values.any())\n",
        "# print(train_data.isnull().sum())\n",
        "# print(test_data.isnull().values.any())\n",
        "# print(test_data.isnull().sum())\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "test_data = test_data.reset_index(drop=True)\n",
        "print(train_data)\n",
        "print(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nkcc6LTuay9x",
        "colab": {}
      },
      "source": [
        "# max_len = 0\n",
        "# a = -1\n",
        "# for s in train_data['document']:\n",
        "#     a += 1\n",
        "#     if a %1000 == 0:\n",
        "#         print(a)\n",
        "#     token = tokenizer.tokenize(s)\n",
        "#     max_len = max(max_len, len(token))\n",
        "\n",
        "# print(max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv4Qb8EYUn2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tokenization.FullTokenizer(\"/content/gdrive/My Drive/ML/HanBert-54kN/vocab_54k.txt\", use_moran=True)\n",
        "\n",
        "cls_token_id = 3\n",
        "sep_token_id = 4\n",
        "MAX_SEQUENCE_LENGTH = 140\n",
        "\n",
        "train_inputs = compute_inputs(train_data, tokenizer, MAX_SEQUENCE_LENGTH)\n",
        "train_outputs = compute_outputs(train_data)\n",
        "test_inputs = compute_inputs(test_data, tokenizer, MAX_SEQUENCE_LENGTH)\n",
        "test_outputs = compute_outputs(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfdLdNdHZNZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_inputs,train_outputs,test_inputs,test_outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwzPPWEmcDoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    ids = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    seg = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    \n",
        "    \n",
        "    config = BertConfig.from_json_file('/content/gdrive/My Drive/ML/HanBert-54kN/bert_config.json')\n",
        "    config.output_hidden_states = False\n",
        "    bert_model = TFBertModel.from_pretrained('/content/gdrive/My Drive/HanBert-54kN-torch.tar/HanBert-54kN-torch', config=config, from_pt=True)\n",
        "    # bert_model = TFBertModel.from_pretrained('/content/drive/My Drive/ML/HanBert-54kN/model.ckpt.index', config=config)\n",
        "\n",
        "    # bert_model = hub.KerasLayer('/content/gdrive/My Drive/ML/HanBert-54kN', trainable=True)\n",
        "    x = bert_model([ids, mask, seg])[0]\n",
        "\n",
        "    \n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[ids, mask, seg,], outputs=x)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxKFc_NCcFLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gkf = GroupKFold(n_splits=5).split(X=train_data.document, groups=train_data.document)\n",
        "\n",
        "history = []\n",
        "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
        "    if fold in [0, 2]:\n",
        "        print(f\"fold : {fold}\")\n",
        "        X_train = [train_inputs[i][train_idx] for i in range(len(train_inputs))]\n",
        "        Y_train = train_outputs[train_idx]\n",
        "\n",
        "        X_valid = [train_inputs[i][valid_idx] for i in range(len(train_inputs))]\n",
        "        Y_valid = train_outputs[valid_idx]\n",
        "        \n",
        "        K.clear_session()\n",
        "        model = create_model()\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "        model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
        "        # model.summary()\n",
        "        history.append(model.fit(X_train,Y_train,\n",
        "                                 validation_data=(X_valid, Y_valid),\n",
        "                                 epochs=3, batch_size=64))\n",
        "        \n",
        "        model.save_weights(f'/content/gdrive/My Drive/ML/HanBert-54kN/tf_model_{fold}.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold : 0",
            '"Model: "model"',
            "__________________________________________________________________________________________________",
            "Layer (type)                    Output Shape         Param #     Connected to                     ",
            "==================================================================================================",
            "input_1 (InputLayer)            [(None, 140)]        0                                            ",
            "__________________________________________________________________________________________________",
            "input_2 (InputLayer)            [(None, 140)]        0                                            ",
            "__________________________________________________________________________________________________",
            "input_3 (InputLayer)            [(None, 140)]        0                                            ",
            "__________________________________________________________________________________________________",
            "tf_bert_model (TFBertModel)     ((None, 140, 768), ( 127513344   input_1[0][0]                    ",
            "                                                                 input_2[0][0]                    ",
            "                                                                 input_3[0][0]                    ",
            "__________________________________________________________________________________________________",
            "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              ",
            "__________________________________________________________________________________________________",
            "dropout_37 (Dropout)            (None, 768)          0           global_average_pooling1d[0][0]   ",
            "__________________________________________________________________________________________________",
            "dense (Dense)                   (None, 1)            769         dropout_37[0][0]                 ",
            "==================================================================================================",
            "Total params: 127,514,113",
            "Trainable params: 127,514,113",
            "Non-trainable params: 0",
            "__________________________________________________________________________________________________",
            "Train on 119996 samples, validate on 29999 samples",
            "Epoch 1/3",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.",
            "119996/119996 [==============================] - 2050s 17ms/sample - loss: 0.3203 - accuracy: 0.8605 - val_loss: 0.2626 - val_accuracy: 0.8936",
            "Epoch 2/3",
            "119996/119996 [==============================] - 2042s 17ms/sample - loss: 0.2411 - accuracy: 0.8997 - val_loss: 0.2504 - val_accuracy: 0.8987",
            "Epoch 3/3",
            "119996/119996 [==============================] - 2043s 17ms/sample - loss: 0.1961 - accuracy: 0.9212 - val_loss: 0.2392 - val_accuracy: 0.9057",
            "fold : 2",
            "Train on 119996 samples, validate on 29999 samples",
            "Epoch 1/3",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.",
            "119996/119996 [==============================] - 2061s 17ms/sample - loss: 0.3280 - accuracy: 0.8577 - val_loss: 0.2624 - val_accuracy: 0.8915",
            "Epoch 2/3",
            "119996/119996 [==============================] - 2047s 17ms/sample - loss: 0.2472 - accuracy: 0.8977 - val_loss: 0.2397 - val_accuracy: 0.9037",
            "Epoch 3/3",
            "119996/119996 [==============================] - 2036s 17ms/sample - loss: 0.2045 - accuracy: 0.9176 - val_loss: 0.2491 - val_accuracy: 0.9008"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU4UAVF8BzbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, h in enumerate(history):\n",
        "    print(f'history : {i}')\n",
        "    epochs = range(1, len(h.history['accuracy']) + 1)\n",
        "    plt.plot(epochs, h.history['loss'])\n",
        "    plt.plot(epochs, h.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWfyeNtovR9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(test_inputs, test_outputs)[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "64af8d6e-4f59-4c1b-d82e-c7fa5bee8e65",
        "id": "UzC32ZU8CGYe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def create_model1():\n",
        "    ids = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    seg = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)\n",
        "    \n",
        "    \n",
        "    config = BertConfig.from_json_file('/content/drive/My Drive/ML/HanBert-54kN/bert_config.json')\n",
        "    config.output_hidden_states = False\n",
        "    bert_model = TFBertModel.from_pretrained('/content/drive/My Drive/ML/HanBert-54kN/tf_hub_model_0.h5', config=config)\n",
        "    x = bert_model([ids, mask, seg])[0]\n",
        "\n",
        "    \n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[ids, mask, seg,], outputs=x)\n",
        "    \n",
        "    return model\n",
        "\n",
        "load_model = create_model1()\n",
        "\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(test_inputs, test_outputs)[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49997/49997 [==============================] - 310s 6ms/sample - loss: 0.2580 - accuracy: 0.8986\n",
            "\n",
            " 테스트 정확도: 0.8986\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
