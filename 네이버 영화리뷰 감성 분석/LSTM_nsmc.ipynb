{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyO1TGRl0kUXn+PzU5v8LIWV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cms5380/project/blob/master/%EB%84%A4%EC%9D%B4%EB%B2%84%20%EC%98%81%ED%99%94%EB%A6%AC%EB%B7%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IADDvdxTjAzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive')\n",
        "!pip install konlpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1TJIsLcjtp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install JPype1==0.7.0\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from konlpy.tag import Okt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I9aq40gjvb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_table('/content/gdrive/My Drive/test/ratings_train.txt')\n",
        "test_data = pd.read_table('/content/gdrive/My Drive/test/ratings_test.txt')\n",
        "\n",
        "\n",
        "train_data['label'].value_counts().plot(kind = 'bar')\n",
        "plt.show()\n",
        "print(train_data.isnull().values.any())\n",
        "print(train_data.isnull().sum())\n",
        "\n",
        "print(train_data.loc[train_data.document.isnull()])\n",
        "train_data = train_data.dropna(how = 'any')\n",
        "print(train_data.isnull().values.any())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTRXjFxljyAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "okt = Okt()\n",
        "\n",
        "X_train = []\n",
        "for sentence in train_data['document']:\n",
        "    temp_X = []\n",
        "    temp_X = okt.morphs(sentence, stem=True)\n",
        "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "    X_train.append(temp_X)\n",
        "\n",
        "\n",
        "print(X_train[:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZR88qtrmMbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = test_data.dropna(how='any') # Null 값 제거\n",
        "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
        "\n",
        "X_test = []\n",
        "for sentence in test_data['document']:\n",
        "    temp_X = []\n",
        "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
        "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "    X_test.append(temp_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElIfvCS0j1L0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_words = 35000\n",
        "tokenizer = Tokenizer(num_words=max_words) # 상위 35,000개의 단어만 보존\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "\n",
        "print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\n",
        "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.xlabel('length of Data')\n",
        "plt.ylabel('number of Data')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1jWBl8Dj5Ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 30\n",
        "# 전체 데이터의 길이는 30으로 맞춘다.\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)\n",
        "\n",
        "y_train = np.array(train_data['label'])\n",
        "y_test = np.array(test_data['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0vHltixi0Uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 100))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train, epochs=4, batch_size=60, validation_split=0.2)\n",
        "\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}